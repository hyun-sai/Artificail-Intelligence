{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iMlANlGdkzd",
        "outputId": "a68b03c2-838b-4a59-ef6f-4f9104e699b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[4585    0   16   11   10   13   44    6   67    2]\n",
            " [   0 5355   24   17    1   37    8    9   81    8]\n",
            " [  42   80 4111   87  107    7  118   94  176   42]\n",
            " [  37   38  138 4343    7  160   51   65  127   68]\n",
            " [  11   30   35    8 4304    7   54   11   70  256]\n",
            " [ 107   58   35  278   97 3427  106   36  239  109]\n",
            " [  48   34   42    5   30   74 4500    3   49    2]\n",
            " [  36   84   85   21   75    8    7 4508   20  166]\n",
            " [  34  151   68  161   35  140   40   26 4082   88]\n",
            " [  42   38   40   96  217   43    5  185   64 4178]]\n",
            "Precision: 0.8849772078801609\n",
            "Recall: 0.8838301445676005\n",
            "F1 Score: 0.8837815276233947\n"
          ]
        }
      ],
      "source": [
        "from re import X\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "mnist=fetch_openml('mnist_784',version=1)\n",
        "m=len(mnist[\"data\"])\n",
        "X = mnist[\"data\"] / 255.0   # 정규화\n",
        "Y = mnist[\"target\"].astype(np.int32)\n",
        "X=X.dropna()\n",
        "Y=Y.dropna()\n",
        "X=(np.array(X)).reshape(m,784)\n",
        "Y=(np.array(Y)).reshape(m,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1004)\n",
        "class LogisticRegression:\n",
        "    def __init__(self,lr=0.5,epochs=100):\n",
        "        self.lr=lr\n",
        "        self.epochs=epochs\n",
        "        self.theta=None\n",
        "    def sigmoid(self,z):\n",
        "        return 1/(1+np.exp(-z))\n",
        "    def compute_loss(self,Y,Y_hat):\n",
        "        m=len(Y)\n",
        "        return -1/m*np.sum(Y*np.log(Y_hat+1e-8)+(1-Y)*np.log(1-Y_hat+1e-8))\n",
        "    def fit(self,X,Y):\n",
        "        m,n=X.shape\n",
        "        X=np.hstack((np.ones((m, 1)), X))\n",
        "        self.theta=np.zeros(n+1).reshape(n+1,1)\n",
        "        losses=[]\n",
        "        for i in range(self.epochs):\n",
        "            z=np.dot(X,self.theta)\n",
        "            Y_hat=self.sigmoid(z)\n",
        "            gradient=(1/m)*X.T.dot(Y_hat-Y) #gradient의 크기를 지정을 안해줌 세타는 해줬는데 회귀에서도\n",
        "            self.theta=self.theta-self.lr*gradient\n",
        "            loss=self.compute_loss(Y,Y_hat)\n",
        "            losses.append(loss)\n",
        "        return losses\n",
        "    def predict_probability(self,X): #Y_hat 출력\n",
        "        m=X.shape[0]\n",
        "        X=np.hstack((np.ones((m, 1)), X))\n",
        "        return self.sigmoid(np.dot(X,self.theta))\n",
        "\n",
        "    def predict(self,X,threshold=0.5):\n",
        "        probability=self.predict_probability(X)\n",
        "        return (probability>=threshold).astype(int)\n",
        "models=[]\n",
        "for digit in range(10):\n",
        "    Y_train_binary=(Y_train==(digit)).astype(int)\n",
        "    model=LogisticRegression(lr=0.5,epochs=100)\n",
        "    model.fit(X_train,Y_train_binary)\n",
        "    models.append(model)\n",
        "train_scores = np.zeros((X_train.shape[0], 10))\n",
        "for digit, model in enumerate(models):\n",
        "    prob = model.predict_probability(X_train)\n",
        "    train_scores[:, digit] = prob.ravel()\n",
        "Y_train_pred = np.argmax(train_scores, axis=1)  # shape: (n_samples,)\n",
        "Y_train_true = Y_train.ravel()\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "cm = confusion_matrix(Y_train_true, Y_train_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "precision = precision_score(Y_train_true, Y_train_pred, average='macro')\n",
        "recall = recall_score(Y_train_true, Y_train_pred, average='macro')\n",
        "f1 = f1_score(Y_train_true, Y_train_pred, average='macro')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    }
  ]
}